{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modell import *\n",
    "from helper import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K \n",
    "\n",
    "num_classes = 4\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "# Reads paths of images together with their labels\n",
    "filename = 'training_combined.csv'\n",
    "image_list, label_list = read_input_file(filename)\n",
    "label_list = np.array(label_list)\n",
    "label_list = np.transpose(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.121875  , 0.17291667, 0.696875  , 0.87916667],\n",
       "       [0.1140625 , 0.30416667, 0.8859375 , 0.73125   ],\n",
       "       [0.0203125 , 0.25833333, 0.8765625 , 0.75416667],\n",
       "       ...,\n",
       "       [0.        , 0.05416667, 0.7578125 , 1.        ],\n",
       "       [0.396875  , 0.06458333, 0.5859375 , 0.93541667],\n",
       "       [0.33125   , 0.21041667, 0.6828125 , 0.94583333]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = image_list[:98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = label_list[:98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, valid_X, train_label, valid_label = train_test_split(image_list, label_list, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78,)\n",
      "(20,)\n",
      "(78, 4)\n",
      "(20, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(valid_X.shape)\n",
    "print(train_label.shape)\n",
    "print(valid_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(features, labels, batch_size):\n",
    "    num_rows = features.shape[0]\n",
    "    # Initialize a counter\n",
    "    \n",
    "    cv_img = []\n",
    "    temp=0\n",
    "    while temp<1:\n",
    "        counter = 0\n",
    "#         print('hi')\n",
    "#         print('hi')\n",
    "#         print('hi')\n",
    "#         print('hi')\n",
    "        # for content, label in zip(features['content'], features['label']):\n",
    "        for i in features:\n",
    "            n = cv2.imread(\"images/\" + i)\n",
    "            # print(i)\n",
    "            cv_img.append(i)\n",
    "            \n",
    "            #X_train[counter%batch_size] = n\n",
    "            #y_train[counter%batch_size] = labels[counter]\n",
    "            counter = counter + 1\n",
    "            if(counter%batch_size == 0):\n",
    "                train = np.array(cv_img)\n",
    "#                 cv_img = cv_img.astype('float32')\n",
    "#                 train = cv_img / 255.\n",
    "                cv_img = None\n",
    "                cv_img = []\n",
    "                print(train, labels[counter-batch_size:counter])\n",
    "            elif counter==num_rows and counter%batch_size < batch_size:\n",
    "                train = np.array(cv_img)\n",
    "#                 cv_img = cv_img.astype('float32')\n",
    "#                 train = cv_img / 255.\n",
    "                cv_img = None\n",
    "                cv_img = []\n",
    "                print ('HI')\n",
    "                print(train, labels[counter-batch_size+1:counter])\n",
    "        temp = temp+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_X, train_label, batch_size)\n",
    "val_generator = generator(valid_X, valid_label, batch_size)\n",
    "\n",
    "train_samples=np.ceil(train_X.shape[0] / batch_size)\n",
    "val_samples=np.ceil(valid_X.shape[0] / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1469052256414DSC_0653.png' '147954714706311.png'] [[0.0578125  0.         1.         1.        ]\n",
      " [0.075      0.09791667 0.925      1.        ]]\n",
      "['1476878834852Untitled1.png' '1470747128351DSC_0256.png'] [[0.1171875  0.11875    0.9875     0.95208333]\n",
      " [0.1953125  0.10208333 0.8578125  0.89583333]]\n",
      "['JPEG_20160526_150511_100091994275.png'\n",
      " '1474264827890cobalt-beyond-the-sea-maxi-dress3.png'] [[0.2640625  0.         0.634375   1.        ]\n",
      " [0.         0.29166667 1.         0.6875    ]]\n",
      "['147437487175911471341993644-Roadster-Cream-Coloured-Printed-T-shirt-8851471341993393-4.png'\n",
      " 'JPEG_20161207_165644_1000961805303.png'] [[0.003125   0.30625    0.996875   0.70625   ]\n",
      " [0.321875   0.29791667 0.7        0.75833333]]\n",
      "['JPEG_20160711_113321_1000235741992.png' '1476881557883Untitled1.png'] [[0.3390625  0.13541667 0.690625   0.96875   ]\n",
      " [0.0203125  0.25833333 0.8765625  0.75416667]]\n",
      "['JPEG_20161117_154532_1000146348308.png'\n",
      " 'JPEG_20160517_140621_1000651031832.png'] [[0.25       0.26458333 0.9234375  0.74791667]\n",
      " [0.121875   0.17291667 0.696875   0.87916667]]\n",
      "['JPEG_20161118_190252_1000475666188.png' '1475009449259DSC020551.png'] [[0.1390625  0.08125    0.7625     0.89375   ]\n",
      " [0.0203125  0.1875     0.971875   0.77083333]]\n",
      "HI\n",
      "['1475559143203mocha-chasing-summer-maxi-dress.png'] [[0.         0.30416667 1.         0.73333333]]\n"
     ]
    }
   ],
   "source": [
    "generator(train_X, train_label, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JPEG_20161126_144054_1000330319257.png' '1471594607670DSC_0103.png'\n",
      " '147771738670920161028_170650.png'\n",
      " 'JPEG_20160820_112743_1000875312594.png'] [[0.0875     0.29166667 0.821875   0.75      ]\n",
      " [0.015625   0.36041667 0.99375    0.65625   ]\n",
      " [0.1359375  0.16666667 1.         1.        ]\n",
      " [0.403125   0.06666667 0.621875   0.98333333]]\n",
      "['1473409219651black-around-about-tunic-dress2.png'\n",
      " '1472630156514m1livi316_charcoal_l_alt_2.png'\n",
      " '1474273419910MS-8502372.png' '1476773560971DSC_8789.png'] [[0.0046875  0.18541667 1.         0.71458333]\n",
      " [0.         0.15416667 0.978125   0.83333333]\n",
      " [0.046875   0.15       1.         1.        ]\n",
      " [0.3140625  0.         0.946875   0.93541667]]\n",
      "['1467893191516DSC_0010.png' 'JPEG_20160607_161754_100010819310.png'\n",
      " '1476878834852Untitled1.png' '1480513991329IMG_0475.png'] [[0.2265625  0.36041667 0.9359375  0.66041667]\n",
      " [0.15       0.275      0.890625   0.73958333]\n",
      " [0.1171875  0.11875    0.9875     0.95208333]\n",
      " [0.0515625  0.21666667 0.78125    0.67291667]]\n",
      "['14581478747652.png'\n",
      " '1469616520171JPEG_20160625_105444_1000414323083.png'\n",
      " '147437487175911471341993644-Roadster-Cream-Coloured-Printed-T-shirt-8851471341993393-4.png'\n",
      " 'JPEG_20160623_144800_1000970763843.png'] [[0.3078125  0.23541667 0.684375   0.75833333]\n",
      " [0.340625   0.35208333 0.884375   0.68541667]\n",
      " [0.003125   0.30625    0.996875   0.70625   ]\n",
      " [0.10625    0.48333333 0.9078125  0.64375   ]]\n",
      "['1467815275518DSC_0191.png' '1473486297514DeeplearnS11797.png'\n",
      " '147394330286111472637793392-Roadster-Men-Navy-Blue-Regular-Fit-Checked-Casual-Shirt-491472637793040-4.png'\n",
      " 'JPEG_20160517_140621_1000651031832.png'] [[0.3296875  0.28958333 0.659375   0.8       ]\n",
      " [0.0546875  0.25208333 0.9328125  0.74166667]\n",
      " [0.         0.29166667 1.         0.73541667]\n",
      " [0.121875   0.17291667 0.696875   0.87916667]]\n",
      "['1480944164079_R2A1976.png' '1474272589082NEL793066.png'\n",
      " '1472824149661DSC_3380.png' 'JPEG_20160929_113805_1000323994545.png'] [[0.321875   0.24375    0.6796875  0.8125    ]\n",
      " [0.0328125  0.08541667 0.89375    0.8875    ]\n",
      " [0.1421875  0.15833333 0.9578125  0.8       ]\n",
      " [0.0140625  0.27083333 0.834375   0.89583333]]\n",
      "['JPEG_20161124_185636_1000504616616.png' '1472553605548DSC_2022.png'\n",
      " 'JPEG_20161118_190252_1000475666188.png'\n",
      " 'JPEG_20160526_132324_1000832397711.png'] [[0.1515625  0.09375    0.721875   0.91458333]\n",
      " [0.0625     0.00416667 0.9359375  0.88125   ]\n",
      " [0.1390625  0.08125    0.7625     0.89375   ]\n",
      " [0.2828125  0.         0.759375   1.        ]]\n",
      "['1479455928674Sin16-11-201611360.png'\n",
      " 'JPEG_20161028_103436_1000918087117.png' '1469516484508DSC_0431_1.png'\n",
      " 'JPEG_20160810_115430_1000314779140.png'] [[0.         0.16666667 1.         0.9375    ]\n",
      " [0.35       0.16875    0.7078125  0.80625   ]\n",
      " [0.0328125  0.07083333 0.975      0.95      ]\n",
      " [0.2890625  0.11041667 0.7        0.91666667]]\n",
      "['1470734265686DSC_0039.png' 'JPEG_20161117_154532_1000146348308.png'\n",
      " 'JPEG_20161123_131331_1000615275006.png'\n",
      " '1480502261060IMG_20161129_193613.png'] [[0.0703125  0.20416667 0.8671875  0.83541667]\n",
      " [0.25       0.26458333 0.9234375  0.74791667]\n",
      " [0.29375    0.02916667 0.653125   0.90208333]\n",
      " [0.0484375  0.17083333 1.         0.73333333]]\n",
      "['1469052256414DSC_0653.png' '1467785369215DSC_0019.png'\n",
      " '1476774482036DSC_8658.png' '1472137733941DSC_0129.png'] [[0.0578125  0.         1.         1.        ]\n",
      " [0.31875    0.21875    0.678125   0.7875    ]\n",
      " [0.1921875  0.         0.846875   0.8875    ]\n",
      " [0.05625    0.07708333 0.946875   1.        ]]\n",
      "['1479747460474SpringField16-11-201610890.png' '1476884855486DSC_6411.png'\n",
      " 'JPEG_20161127_173150_1000534550405.png'\n",
      " '1480176547431Kraus22-11-1613931.png'] [[0.0015625  0.21458333 1.         0.85833333]\n",
      " [0.284375   0.23333333 0.9234375  0.74166667]\n",
      " [0.3515625  0.15       0.61875    0.83958333]\n",
      " [0.0828125  0.29791667 0.9671875  0.72708333]]\n",
      "['JPEG_20161025_124252_1000655486064.png' '147954714706311.png'\n",
      " '1475158045358DSC06932.png'\n",
      " '147444877948011471678765025-Roadster-Men-Light-Brown-Printed-T-shirt-4741471678764782-2.png'] [[0.096875   0.15208333 0.825      0.91458333]\n",
      " [0.075      0.09791667 0.925      1.        ]\n",
      " [0.10625    0.0625     0.971875   0.85833333]\n",
      " [0.         0.15208333 1.         0.87291667]]\n",
      "['147437508529811470139727518-Roadster-Navy-Hooded-Sweatshirt-6141470139727398-5.png'\n",
      " 'JPEG_20160823_121917_1000911636586.png' '1474118108544BRT467334.png'\n",
      " '1462875765003DSC_0487.png'] [[0.         0.         1.         1.        ]\n",
      " [0.096875   0.06458333 0.8484375  0.92916667]\n",
      " [0.0265625  0.13541667 0.978125   0.88958333]\n",
      " [0.415625   0.18333333 0.75       0.5875    ]]\n",
      "['JPEG_20160611_120832_1000308675808.png'\n",
      " 'JPEG_20161128_170230_1000366955179.png'\n",
      " '1475559143203mocha-chasing-summer-maxi-dress.png'\n",
      " '1473231510890DeeplearnS11456.png'] [[0.1046875  0.20833333 0.896875   0.73125   ]\n",
      " [0.0546875  0.375      0.90625    0.72708333]\n",
      " [0.         0.30416667 1.         0.73333333]\n",
      " [0.1140625  0.30416667 0.8859375  0.73125   ]]\n",
      "['1467896178064DSC_0958.png' 'JPEG_20161123_181824_1000611096667.png'\n",
      " 'JPEG_20160629_162656_1000960108789.png'\n",
      " 'JPEG_20161210_125104_1000144436971.png'] [[0.096875   0.26458333 0.9640625  0.7375    ]\n",
      " [0.4578125  0.14583333 0.6125     0.875     ]\n",
      " [0.1203125  0.42916667 0.7140625  0.85      ]\n",
      " [0.1015625  0.11041667 0.83125    0.76875   ]]\n",
      "['147436763182011469615979143-Roadster-Blue-Skinny-Fit-Jeans-7871469615978787-1.png'\n",
      " 'JPEG_20161124_171639_1000992177080.png' '1476881557883Untitled1.png'\n",
      " '1474264604326coral-happily-ever-after-day-dress4.png'] [[0.         0.17916667 1.         0.75625   ]\n",
      " [0.340625   0.14791667 0.7078125  0.79375   ]\n",
      " [0.0203125  0.25833333 0.8765625  0.75416667]\n",
      " [0.         0.31666667 1.         0.69375   ]]\n",
      "['147323534845259859_XXX_v1.png' 'JPEG_20160907_155530_1000157912079.png'\n",
      " '1474636817133DSC06477.png' '1473317684684DeeplearnS11226.png'] [[0.1421875  0.         0.7203125  1.        ]\n",
      " [0.3203125  0.075      0.85625    0.92083333]\n",
      " [0.0265625  0.12916667 0.959375   0.5875    ]\n",
      " [0.178125   0.         0.825      1.        ]]\n",
      "['1472826035474DSC_3497.png' '147771707740120161028_153434.png'\n",
      " '1475156977768DSC06936.png'\n",
      " '147445039931011472642879846-Roadster-Women-Green-Checked-Shirt-Dress-5591472642879643-2.png'] [[0.33125    0.41875    0.5015625  0.62708333]\n",
      " [0.15       0.01875    0.7921875  0.82291667]\n",
      " [0.309375   0.12083333 0.6625     0.9       ]\n",
      " [0.         0.22291667 0.9984375  0.80208333]]\n",
      "['JPEG_20160625_165009_1000802034298.png'\n",
      " 'JPEG_20161007_152608_1000228164735.png' '1475009449259DSC020551.png'\n",
      " '1480510999675IMG_0247.png'] [[0.21875    0.34375    0.8671875  0.66041667]\n",
      " [0.065625   0.325      0.9453125  0.72291667]\n",
      " [0.0203125  0.1875     0.971875   0.77083333]\n",
      " [0.1515625  0.075      0.7234375  0.77916667]]\n",
      "['147742431796620161025_142621.png' '147772369111320161028_164048.png'] [[0.15625    0.325      0.703125   0.7       ]\n",
      " [0.225      0.05       0.7453125  0.52708333]]\n"
     ]
    }
   ],
   "source": [
    "features = train_X\n",
    "labels = train_label\n",
    "\n",
    "num_rows = features.shape[0]\n",
    "\n",
    "cv_img = []\n",
    "temp=0\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in features:\n",
    "    n = cv2.imread(\"images/\" + i)\n",
    "    # print(i)\n",
    "    cv_img.append(i)\n",
    "    counter = counter + 1\n",
    "    if(counter%batch_size == 0):\n",
    "        train = np.array(cv_img)\n",
    "        cv_img = None\n",
    "        cv_img = []\n",
    "        print(train, labels[counter-batch_size:counter])\n",
    "    elif counter==num_rows:\n",
    "        train = np.array(cv_img)\n",
    "        print(train, labels[counter-counter%batch_size:counter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0578125 , 0.        , 1.        , 1.        ],\n",
       "       [0.075     , 0.09791667, 0.925     , 1.        ],\n",
       "       [0.1171875 , 0.11875   , 0.9875    , 0.95208333],\n",
       "       [0.1953125 , 0.10208333, 0.8578125 , 0.89583333],\n",
       "       [0.2640625 , 0.        , 0.634375  , 1.        ],\n",
       "       [0.        , 0.29166667, 1.        , 0.6875    ],\n",
       "       [0.003125  , 0.30625   , 0.996875  , 0.70625   ],\n",
       "       [0.321875  , 0.29791667, 0.7       , 0.75833333],\n",
       "       [0.3390625 , 0.13541667, 0.690625  , 0.96875   ],\n",
       "       [0.0203125 , 0.25833333, 0.8765625 , 0.75416667],\n",
       "       [0.25      , 0.26458333, 0.9234375 , 0.74791667],\n",
       "       [0.121875  , 0.17291667, 0.696875  , 0.87916667],\n",
       "       [0.1390625 , 0.08125   , 0.7625    , 0.89375   ],\n",
       "       [0.0203125 , 0.1875    , 0.971875  , 0.77083333],\n",
       "       [0.        , 0.30416667, 1.        , 0.73333333]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        for i in features:\n",
    "            n = cv2.imread(\"images/\" + i)\n",
    "            # print(i)\n",
    "            cv_img.append(i)\n",
    "            \n",
    "            #X_train[counter%batch_size] = n\n",
    "            #y_train[counter%batch_size] = labels[counter]\n",
    "            counter = counter + 1\n",
    "            if(counter%batch_size == 0):\n",
    "                train = np.array(cv_img)\n",
    "#                 cv_img = cv_img.astype('float32')\n",
    "#                 train = cv_img / 255.\n",
    "                cv_img = None\n",
    "                cv_img = []\n",
    "                print(train, labels[counter-batch_size:counter])\n",
    "            elif counter==num_rows and counter%batch_size < batch_size:\n",
    "                train = np.array(cv_img)\n",
    "#                 cv_img = cv_img.astype('float32')\n",
    "#                 train = cv_img / 255.\n",
    "                cv_img = None\n",
    "                cv_img = []\n",
    "                print ('HI')\n",
    "                print(train, labels[counter-batch_size+1:counter])\n",
    "        temp = temp+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = ResnetBuilder.build_resnet_9((3, 480, 640), 4)\n",
    "model.compile(loss=keras.losses.mse, optimizer=keras.optimizers.Adam(), metrics=['mse', bb_intersection_over_union])\n",
    "model.fit_generator(train_generator, steps_per_epoch=train_samples, epochs=1, verbose=1, \n",
    "                    validation_data=val_generator, validation_steps=val_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[3]:\n",
    "\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model_1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_1.h5\")\n",
    "print(\"Saved\")\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "json_file = open('model_1.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(\"model_1.h5\")\n",
    "print(\"Loaded\")\n",
    "model.compile(loss=keras.losses.mse, optimizer=keras.optimizers.Adam(), metrics=['mse', bb_intersection_over_union])\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('test.csv')\n",
    "\n",
    "test = df1['image_name']\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def generator(features, labels, batch_size):\n",
    "    num_rows = features.shape[0]\n",
    "    # Initialize a counter\n",
    "    counter = 0\n",
    "    cv_img = []\n",
    "    while True:\n",
    "        # for content, label in zip(features['content'], features['label']):\n",
    "        for i in features:\n",
    "            n = cv2.imread(\"images/\" + i)\n",
    "            #print(i)\n",
    "            cv_img.append(n)\n",
    "            \n",
    "            #X_train[counter%batch_size] = n\n",
    "            #y_train[counter%batch_size] = labels[counter]\n",
    "            counter = counter + 1\n",
    "            if(counter%batch_size == 0):\n",
    "                cv_img = np.array(cv_img)\n",
    "                cv_img = cv_img.astype('float32')\n",
    "                train = cv_img / 255.\n",
    "                cv_img = None\n",
    "                cv_img = []\n",
    "                yield train, labels[counter-batch_size:counter]\n",
    "\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "\n",
    "def test_generator(features, batch_size):\n",
    "    num_rows = features.shape[0]\n",
    "    counter = 0\n",
    "    cv_img = []\n",
    "    # Initialize a counter\n",
    "    while True:\n",
    "        for i in features:\n",
    "            n = cv2.imread(\"images/\" + i)\n",
    "            cv_img.append(n)\n",
    "            counter = counter + 1\n",
    "            if (counter%batch_size == 0):\n",
    "                cv_img = np.array(cv_img)\n",
    "                cv_img = cv_img.astype('float32')\n",
    "                test1 = cv_img / 255.\n",
    "                cv_img = None\n",
    "                cv_img = []\n",
    "                yield test1\n",
    "\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "\n",
    "test_samples=np.ceil(test.shape[0] / batch_size)\n",
    "\n",
    "pred = model.predict_generator(test_generator(test, batch_size), steps=test_samples, verbose=1)\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "pred.shape\n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "test.shape\n",
    "\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "\n",
    "pred[0]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "[0.23278953 0.29601428 0.80433834 0.7575191 ]\n",
    "[0.23278953 0.29601428 0.80433834 0.7575191 ]\n",
    "\n",
    "\n",
    "# In[49]:\n",
    "\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    print(pred[i])\n",
    "\n",
    "\n",
    "# In[50]:\n",
    "\n",
    "\n",
    "xf1 = np.floor(640*pred[:,0])\n",
    "yf1 = np.floor(480*pred[:,1])\n",
    "xf2 = np.floor(640*pred[:,2])\n",
    "yf2 = np.floor(480*pred[:,3])\n",
    "\n",
    "\n",
    "# In[51]:\n",
    "\n",
    "\n",
    "final_labels = np.transpose(np.vstack((xf1,xf2,yf1,yf2)))\n",
    "\n",
    "\n",
    "# In[57]:\n",
    "\n",
    "\n",
    "final_labels_new = final_labels[:-1]\n",
    "final_labels_new1 = final_labels[1:]\n",
    "\n",
    "\n",
    "# In[61]:\n",
    "\n",
    "\n",
    "final_labels_new.shape\n",
    "\n",
    "\n",
    "# In[60]:\n",
    "\n",
    "\n",
    "final_labels_new1.shape\n",
    "\n",
    "\n",
    "# In[64]:\n",
    "\n",
    "\n",
    "df1['x1'] = pd.DataFrame(final_labels_new1[:,0])\n",
    "df1['x2'] = pd.DataFrame(final_labels_new1[:,1])\n",
    "df1['y1'] = pd.DataFrame(final_labels_new1[:,2])\n",
    "df1['y2'] = pd.DataFrame(final_labels_new1[:,3])\n",
    "\n",
    "df1.to_csv('test2.csv',index=False)\n",
    "\n",
    "\n",
    "# In[63]:\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({'fname': test.path.tolist(), 'label': labels})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
